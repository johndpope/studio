{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuPhtpzB0le9"
   },
   "source": [
    "# Setup Google Colab\n",
    "\n",
    "Mount Google Drive, check the hardware accelerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W8pIoTpr034d"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LuMHkIOd1J50"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEE75y5zy1NP"
   },
   "source": [
    "# Setup Linux\n",
    "\n",
    "Upgrade pip and setuptools; install Cairo; install my studio packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fl65JKy4QCMP"
   },
   "outputs": [],
   "source": [
    "!pip install -q --upgrade pip setuptools\n",
    "!apt-get install libcairo2-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abgTFGudSDyQ"
   },
   "source": [
    "# Load DALL-E Mini\n",
    "\n",
    "## [The DALL-E Experiment](https://wandb.ai/dalle-mini/dalle-mini/reports/DALL-E-mini--Vmlldzo4NjIxODA)\n",
    "> As part of the FLAX/JAX community week organized by ðŸ¤— Hugging Face and the Google Cloud team, we worked on reproducing the results of OpenAI's DALLÂ·E with a smaller architecture. DALL-E can generate new images from any text prompt.\n",
    "\n",
    "This is a recreation of the original DALL-E model, available for free (!!) as a Python library. I've wrapped it a bit so you can give it a string and get back PIL (maybe Cairo too?) images.\n",
    "\n",
    "You will need to download the weights, which are large. This code assumes you've already downloaded them to a particular path on your Google Drive; if you haven't, you will need to edit the code to provide another path. I've included several paths from the Weights & Biases website which should be able to download the weights dynamically. To be honest though, it never worked for me and I had to do it manually.\n",
    "\n",
    "---\n",
    "\n",
    "At first DALL-E Mega worked fine, but lately I've been having trouble running it on a P100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xkcOLDqNFrUO"
   },
   "outputs": [],
   "source": [
    "!pip install -q --log dalle-mini-util_install_log \"git+https://github.com/0xmaddie/studio.git#egg=dalle-mini-util&subdirectory=0001-dalle-mini-util\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2QGbNe35EOc"
   },
   "outputs": [],
   "source": [
    "from dalle_mini_util import TextToImageModel\n",
    "\n",
    "dalle_mega_drive_path = \"./drive/MyDrive/AI/models/dalle_mega\"\n",
    "dalle_mini_drive_path = \"./drive/MyDrive/AI/models/dalle_mini\"\n",
    "\n",
    "# The original DALL-E Mini notebook claims these strings will cause\n",
    "# the DALL-E Mini library to download the weights dynamically from\n",
    "# the Weights & Biases website. I did download the weights from\n",
    "# Weights & Biases, but these strings never worked for me. I had to\n",
    "# go to the website, get the links to the files, and download them\n",
    "# to my drive with cURL.\n",
    "dalle_mega_wandb_path = \"dalle-mini/dalle-mini/mega-1-fp16:latest\"\n",
    "dalle_mini_wandb_path = \"dalle-mini/dalle-mini/mini-1:v0\"\n",
    "\n",
    "vqgan_drive_path = \"./drive/MyDrive/AI/models/vqgan\"\n",
    "vqgan_wandb_path = \"dalle-mini/vqgan_imagenet_f16_16384\"\n",
    "\n",
    "dalle_model_path = dalle_mega_drive_path\n",
    "vqgan_model_path = vqgan_drive_path\n",
    "# Since I load VQGAN from Google Drive, I don't actually use the\n",
    "# commit id in dalle-mini-util, so there's no way to provide it atm.\n",
    "# vqgan_commit_id = \"e93a26e7707683d349bf5d5c41c5b0ef69b677a9\"\n",
    "\n",
    "print(f\"Trying to load DALL-E model at {dalle_model_path}...\")\n",
    "model = TextToImageModel(dalle_model_path, vqgan_model_path)\n",
    "print(f\"Loaded DALL-E model at {dalle_model_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aBHcJ5SWJTmr"
   },
   "source": [
    "# Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-8b1wcgjEgj"
   },
   "outputs": [],
   "source": [
    "from dalle_mini_util import make_image_grid\n",
    "\n",
    "generated_images = []\n",
    "\n",
    "prompt = \"A beautiful acrylic painting of the perfect breakfast.\"\n",
    "\n",
    "print(f\"Generating images with model path {dalle_model_path}.\")\n",
    "print(f\"Prompt: {prompt}\")\n",
    "for image in model.generate(prompt):\n",
    "  display(image)\n",
    "  generated_images.append(image)\n",
    "\n",
    "image_grid = make_image_grid(generated_images)\n",
    "display(image_grid)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyORiJ7pV6HaBgqW40hnMcEM",
   "collapsed_sections": [],
   "mount_file_id": "14qMTY7-ZMbt_BkMJxLjiuZ7PIzQXtDON",
   "name": "0001-dalle.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
